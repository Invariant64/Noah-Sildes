# 线上监考系统设计调研

## 人脸识别综述

### 1. 人脸识别分类

#### 1.1 按应用方式分类

人脸识别按照应用方式，分为 1:1、1:N、M:N。

1:1 人脸识别一般称为 FaceVerification（人脸验证；人脸确认；人脸校验），属于二分类问题，应用场景主要有互联网买机票、车票，医院挂号，政府惠民工程项目，以及各种证券开户、电信开户、互联网金融开户等等。

1:N 人脸识别一般称为 FaceIdentification（人脸识别），属于多分类问题。跟 1:1 的 A/B 两张照片比对最大的区别是一次识别需要与集合所有样本进行比对，数据总量越大计算速度越慢，而总和超过 20 万，就会出现多个相似结果（20 万人这个大数会导致有不少人长相相似），需要人工辅助定位。一般用于疑犯追逃、失踪人口搜寻等领域，以助于减少人工工作量，提高工作效率。

M:N 人脸识别实际上是基于 1:N 的算法，对输入图像中所有人脸与人脸数据底库进行 1:N 匹配。

#### 1.2 按素材使用分类

人脸识别按照素材使用，分为 2D 人脸识别、3D 人脸识别。

2D 人脸识别一般指利用人脸图像的RGB信息进行素材，进行人脸检测、特征提取和信息比对。人脸识别技术研究现状综述

3D 人脸识别使用的素材以点云数据为主，另外还体素网格、三角网格、多视角图等。点云数据由三维空间的坐标点以及各点的颜色组成（XYZRGB），这决定了点云的一个元素里要存的字段内容和大小。数据结构定义可以根据自己使用来重新定义。点云是一种表达方式是非常接近原始传感器的数据集，可以比较完整的表示出物体的三维信息。

### 2. 人脸识别的流程

#### 2.1 2D和3D人脸识别流程对比

![img](https://docimg7.docs.qq.com/image/AgAAETeNgCrg8UQ93wpHdIbbxSFbARGk.png?w=1360&h=509)

#### 2.2 2D人脸识别流程

2D人脸识别流程主要分为图像采集、图像素材获取、人脸检测、特征提取和信息比对。

2D 人脸识别所需的图像素材通过普通摄像头获取，经过图像预处理后，即可作为素材进行使用。人脸图像的预处理的目的，是规范化图像质量，以提高人脸特征提取的准确度。常见的用于人脸图像预处理的操作有调整明暗、裁剪、滤波、旋转等，可以使得采集到的图像能够更有利于对人脸图像进行特征提取。目前主要使用的图像预处理手段有调整灰度、滤波、尺寸归一化等。

（1）调整灰度：指通过调整图像灰度，来平滑处理由于地点、设备、光照等方面因素导致的差异，常用方法有平均值法、直方图变换法、幂次变换法、对数变换法等。

（2）滤波：指通过均值滤波或中值滤波等方法，过滤掉图像采集时环境中电磁信号以及图像传输时产生的电磁干扰对图像的影响，其中，中值滤波使用最为普遍。

（3）尺寸归一化：由于人脸识别算法对人脸图像的宽高有固 定要求，因此通过尺寸归一化可以有利于后续人脸识别算法的处理，常见的尺寸归一化算法有双三次插值法、双线性插值法、最近邻插 值法和立方卷积法等。 

人脸检测主要包括特征点定位、人脸对齐等操作。人脸检测是指对采集到的图像按照一定的纹理特征或深度特征进行人脸搜索， 判断是否存在人脸，并标定每张人脸所处位置、大小与方向姿态的过程。通过人脸检测，可以达到人脸图像精准采集的目的。 

目前的人脸检测方法可分为三类，分别是基于肤色模型的检测、 基于边缘特征的检测、基于统计理论方法的检测。 

（1）肤色用于人脸检测时，主要采用高斯模型、高斯混合模 型在不同颜色空间中建立肤色模型，或使用非参数估计实现基于肤色的人脸检测。

（2）基于边缘特征的检测主要指利用脸部轮廓及五官等存在明显边缘的区域，来实现人脸定位，这种方法计算量相对较小，多用于实时检测。

（3）基于统计理论方法的检测主要是基于 Haar 特征，用 Adaboost 对大量弱分类器进行集成，获得一个强分类器。

目前人脸特征提取所使用的特征主要分为视觉特征和像素特征。自2014年DeepFace 和 DeepID 的提出，目前人脸识别的研究重点已转向深度学习。深度学习人脸识别所用的特征主要为像素特征。 

信息比对是对不同目标的人脸特征进行特征距离计算，目前主流的特征距离计算方式有欧氏距离、余弦距离，除了这两个常用距离外，还有曼哈顿距离、明可夫斯基距离、皮尔森相关系数、斯皮尔曼等级相关系数等也可用作特征距离计算。

#### 2.3 3D人脸识别流程

3D 人脸识别流程主要分为图像采集、图像素材获取、配准、3D 重建、人脸检测、特征提取和信息比对。图像采集主要分为两种：

（1）普通摄像头进行 RGB 图像采集；

（2）使用专用摄像头（3D 结构光、TOF、双目等）进行 RGB图像 + 深度信息采集。

图像素材获取则是从摄像头采集的信息中心提取出 RGB 图像或 RGB 图像 + 深度信息图像。

如果采集的素材为RGB图像+深度信息图像，则需要进行配准。由于 3D 人脸识别中 RGB 素材和深度素材通常由不同摄像头模组采集，故需对不同模组采集到的 RGB 数据与深度数据进行对准，保证每个点的 RGB 数据和深度数据可以对应，并且时间上为同一时刻。配准具体分为时间配准和空间配准。时间配准保证使用的两个模组采集的图像数据在时间上是同步的。空间配准保证 RGB 像素点与该像素点对应的深度数据能够一一对应。

### 3. 人脸识别的方法

#### 3.1 无遮挡的人脸识别方法

##### 3.1.1 基于几何特征的方法

基于几何特征的方法是一种比较直观且常用于早期人脸识别的传统方法，通常需要和其他辅助算法结合使用才可以获得更好的效果。

基于该方法的人脸识别系统主要提取人脸的主要几何特征点（如面部轮廓等）、面部主要器官连续形状、几何特征曲率等信息进行识别。人面部不能完全近似为刚体的特性为几何特征的提取带来了较高的复杂度和难度。

优点：①理解难度低，其应用原理与人脸识别区别不大，能够降低理解的难度，促使用户可以更加容易的理解；②存储空间小，基于几何特征的人脸识别算法可以减少资源存储空间，基本上不占据多余空间，往往只需存储被检测人脸的一个相关特征矢量就可以；③不受光照条件的影响，这种识别方式不需考虑光照条件，在强光、弱光中都能实现。

缺点：①检测准确性不够高，在待测人脸图像中抽取特征有较大的难度；②这个方法只描述了人脸特征的基本形状与结构关系，很多细节信息被忽略，识别率不高，近年来应用范围也越来越小。

##### 3.1.2 基于代数特征的方法

此类方法从代数特征的角度出发，相较于基于几何特征的方法，其优势在于对光照和人的表情变化有一定的包容度。彭辉等改进 K-L 变换进行人脸识别。该方法的核心为分层次的最小距离分类器，其识别率达到 86.13%、91.06%。

##### 3.1.3 基于特征子空间的方法

基于特征子空间的方法是一种将人脸的二维图像通过变换调整到另外的空间中，从而便于在其他空间中处理非人脸特征同人脸特征之间的区别的处理方法。其常用的算法有主元分析法（又称 K-L 变换法）、因子分解法、Fisher 准则方法、小波变换等。

##### 3.1.4 基于双模态融合的方法

基于双模态融合的方法同时运用二维和三维两个模态的信息，可以在信号层、特征层、决策层进行融合，从而获得比单模态更优的识别效果。

#### 3.2 有遮挡的人脸识别方法

##### 3.2.1 基于子空间回归方法

基于子空间回归方法的核心思想是待识别人脸样本是否能回归落到他所属的子空间之中。对遮挡环境下人脸图像的识别问题即可看作是无遮挡图像和遮挡图像所属子空间的回归问题。人脸图像之间本身带有的高度相关性，再加上遮挡物的干扰，就必须考虑清楚遮挡子空间和人脸子空间相关性如何去除。目前方法有稀疏表示法、协同表示法和对遮挡字典处理法。

①稀疏表示法：基本原理是对有遮挡的人脸进行分类，将待识别图像表示为稀疏图像得线性组合，在此基础上有针对人脸对齐和光照问题提出的鲁棒SRC算法、根据人脸五官的遮挡情况提出的分块稀疏表示法（强调人脸的局部特征）、针对样本训练量少的人脸识别提出的基于梯度方向的分层自适应稀疏低秩模型。

②协同表示法：基本思想是不同的人脸存在一定相似性，将待识别图像看成所有训练数据的线性组合，解决了稀疏表示法在实际应用中训练样本少、计算残差大的问题。

③遮挡字典处理法：基本原理是对原始的数据提炼，得到既能表达原有训练数据又能对图像进行识别的新字典。

该模型在小面积遮挡的人脸识别中取得了显著效果，但识别过程残差较大，并且影响重构图像的准确性。

##### 3.2.2 基于结构化误差编码的方法

由实物遮挡引起的误差一般具有一定的空间结构（比如墨镜遮挡、围巾遮挡等），这与由高斯噪声引起的误差不同。结构化误差编码是一类常用解决方法，常见的编码思路有构造遮挡字典、利用反向表示分离出遮挡等。

##### 3.2.3 基于“浅层”鲁棒特征提取的方法

“浅层”鲁棒特征提取的主要思想是依据人为设计的 “浅层”特征提取相关的人脸识别特征，但对光照遮挡和实物遮挡混合出现的情况鲁棒性差。

##### 3.2.4 基于深度学习的方法

人脸识别有遮挡的人脸图像是通过理解人脸图像中的高阶属性实现的。深度学习具有从输入层到输出层的多层非线性映射和基于反向传播的反馈学习机制，非常适合解决这类常规分类器无法比拟的变换问题。深度网络具有稳定强大的分布式表达能力，因此可以设计合理的网络完成人脸识别的任务。由于深度学习的自动学习特点所提取出的“深度”特征具有更强的表达能力和鲁棒性，因此深度学习被逐渐应用于遮挡环境下的人脸识别，这使提取人脸的“深层”特征成为解决遮挡人脸识别的关键。

##### 3.2.5 基于迭代权重误差编码的方法

由视觉经验可知，当人眼对有遮挡的人脸图像进行识别时，往往只会简单地把被遮挡部分忽略，不去理解遮挡区域的内容，然后根据未遮挡的部分进行识别。迭代权重误差编码根据遮挡图像与原图的局部相似性和遮挡误差的空间连续性估计遮挡的位置，对误差信息迭代地赋予不同的权重以消除遮挡区域的影响



## 人体动作姿态识别综述

### 1. 人体动作姿态的分类

人体运动的识别可以大致分为两种：姿态识别和动作过程识别。

#### 1.1 姿态识别

姿态识别的对象为静态系统，主要是识别人体整体或者某一部位的姿势。根据识别对象的不同，又可分为手型识别、体势识别、头部姿态识别等。

#### 1.2 动作识别

动作识别的对象是人体运动的动态过程，例如人体的动作识别、步法识别、手势识别等。

### 2. 人体动作姿态识别的方法

人体动作姿态的识别方法可分为三类：基于统计的方法、基于模板的方法和基于语法的方法。

#### 2.1 基于统计的方法

基于统计的方法是动态识别系统中效果最好的方法，目前主要是隐马尔可夫模型(HMMs)和动态贝叶斯网络(DBN)两种方法。

##### 2.1.1 隐马尔可夫模型

隐马尔可夫模型是目前应用最广的一种方法。HMMs由状态和观测两部分组成，是一种基于转移概率和传输概率的随机模型，系统当前所处状态的概率只与前一个时刻的状态有关，与其它历史状态条件无关。在HMMs的识别过程中，首先提取出特征向量序列，然后通过学习算法进行模型参数训练，最后对未知的运动序列进行识别分类。

##### 2.1.2 动态贝叶斯网络(DBN)

动态贝叶斯网络能够学习变量间的概率依存关系及其随时间变化的规律，具有很好 的可扩展性和可解释性，对于多信息融合推理、多物体动态系统识别非常有效。

#### 2.2 基于模板的方法

基于模板的方法主要是模板匹配法、动态时空规整法和动态规划法。

##### 2.2.1 模板匹配法

模板匹配法的思想是首先对人体动作姿态进行训练建立模板库，然后将待识别的动作姿态与模板进行匹配，计算二者之间的相似度。模板匹配法的优点是实现起来比较简单、计算复杂度较低，缺点是对噪声和动作姿态持续时间的变化 比较敏感。

##### 2.2.2 动态时空规整法

动态时空规整法是一种非线性时间规整方法，它是将待识别的人体动作姿态模板的时间轴非线性地映射到训练模板的时间轴上，从而能够使两者的距离最小。动态时空规整法较好地解决了人体动作姿态在时间尺度上的不确定性。

##### 2.2.3 动态规划法

在动态规划算法的识别过程中，待识别样本模板中的每个时刻特征可以与特征模板中的任意时刻特征进行匹配，二者都无须进行时间规整，但要求必须顺序进行。动态规划算法的主要缺点是计算量会随着训练样本数目的增加而增加。



## 现有案例分析

1. **[智慧教室在线监考系统](https://github.com/hongyaohongyao/smart_classroom_system)**

[![image-20220607005734673](https://github.com/hongyaohongyao/smart_classroom_system/raw/master/.img/README/image-20220607005734673.png)](https://github.com/hongyaohongyao/smart_classroom_system/blob/master/.img/README/image-20220607005734673.png)

* 实现功能
  * 该系统可实现考生人脸信息上传、考生点名、作弊检测等功能。
  * 人脸信息上传及考生点名
    * 通过提前向系统中上传学生的人脸及对应的考生信息，通过人脸识别技术，实现考生点名及考试过程中对考生的实时监测。
  * 作弊检测
    * 通过计算机视觉技术，实时分析考生考试过程中的关节姿态信息，并将姿态进行分类，实现对作弊动作的检测。

* 框架

  * 系统为前后端分离设计，框架大致分为展示层、业务层、算法层和数据层。

  * 展示层（前端）
    * 用户通过展示层与系统进行交互，展示层将获取到的信息传输至后端服务器进行处理，并展示服务器处理好的数据。

  * 业务层
    * 业务层为负责系统大部分的数据管理和资源调度的后台服务器。用户通过前端访问业务层，实现对数据的增删改查等功能。

  * 算法层
    * 算法层为一个算法应用服务器，部署了训练好的深度学习模型，通过实时检测视频画面，实现对考生的监考。

  * 数据库层
    * 数据库层负责存储系统数据。

